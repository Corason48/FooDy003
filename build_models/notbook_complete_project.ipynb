{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2-2ouIxKgg",
        "outputId": "c9ec937e-ddf6-455e-d47e-ec6fbd6348f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak, sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I21yh9OYyT2r"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"going_modular\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23IXP7YOxwuS",
        "outputId": "affb06f9-a1d8-4a9a-e918-7bb022a93b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoaders for\n",
        "image classification data.\n",
        "\"\"\"\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "  \"\"\"Creates training and testing DataLoaders.\n",
        "  \"\"\"\n",
        "  # Use ImageFolder to create dataset(s)\n",
        "  train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "  # Get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn images into data loaders\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False, # don't need to shuffle test data\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb2fZbFdyWsS"
      },
      "outputs": [],
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model.\n",
        "\"\"\"\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates the TinyVGG architecture.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "      super().__init__()\n",
        "      self.conv_block_1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=input_shape,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=hidden_units,\n",
        "                    out_channels=hidden_units,\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2,\n",
        "                        stride=2)\n",
        "      )\n",
        "      self.conv_block_2 = nn.Sequential(\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2)\n",
        "      )\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          # Where did this in_features shape come from?\n",
        "          # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
        "          nn.Linear(in_features=hidden_units*13*13,\n",
        "                    out_features=output_shape)\n",
        "      )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "      x = self.conv_block_1(x)\n",
        "      x = self.conv_block_2(x)\n",
        "      x = self.classifier(x)\n",
        "      return x\n",
        "      # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbLsC8wBz08t",
        "outputId": "e2912664-3873-4c82-850b-d426f773dc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metric across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Tests a PyTorch model for a single epoch.\n",
        "  \"\"\"\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(dataloader):\n",
        "          # Send data to target device\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(X)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, y)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          patience: int = 7,\n",
        "          name=None,\n",
        "           scheduler=None) -> Dict[str, List]:\n",
        "  \"\"\"Trains and tests a PyTorch model with early stopping support.\"\"\"\n",
        "\n",
        "  results = {\n",
        "      \"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": []\n",
        "  }\n",
        "\n",
        "  best_loss = float(\"inf\")\n",
        "  patience_counter = 0\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc = train_step(\n",
        "          model=model,\n",
        "          dataloader=train_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          optimizer=optimizer,\n",
        "          device=device\n",
        "      )\n",
        "\n",
        "      test_loss, test_acc = test_step(\n",
        "          model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device\n",
        "      )\n",
        "\n",
        "      # Print epoch results\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1}/{epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {test_loss:.4f} | Val Acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "      # Save metrics\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "      if scheduler:\n",
        "          scheduler.step(test_loss)\n",
        "\n",
        "      # --- Early Stopping Logic ---\n",
        "      if test_loss < best_loss:\n",
        "          best_loss = test_loss\n",
        "          patience_counter = 0\n",
        "          torch.save(model.state_dict(), \"best_\"+name+\"_\"+str(epoch)+\".pth\")\n",
        "          print(\"✅ Validation loss improved — best model saved.\")\n",
        "      else:\n",
        "          patience_counter += 1\n",
        "          print(f\"⚠️ No improvement for {patience_counter} epoch(s).\")\n",
        "\n",
        "      if patience_counter >= patience:\n",
        "          print(f\"\\n⏹️ Early stopping triggered at epoch {epoch+1}.\")\n",
        "          break\n",
        "\n",
        "  print(\"\\nTraining complete.\")\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJt5kYFm0Hvi"
      },
      "outputs": [],
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\"\"\"\n",
        "Contains various utility functions for PyTorch model training and saving.\n",
        "\"\"\"\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "  \"\"\"Saves a PyTorch model to a target directory.\n",
        "  \"\"\"\n",
        "  # Create target directory\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  # Save the model state_dict()\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qF0KqyX0eJY",
        "outputId": "36364a13-b8a2-44e5-eac2-cb0f106e1e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import data_setup, engine, model_builder, utils\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 5e-4\n",
        "WEIGHT_DECAY=1e-4\n",
        "# Setup directories\n",
        "train_dir = \"data/pizza_steak_sushi/train\"\n",
        "test_dir = \"data/pizza_steak_sushi/test\"\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create DataLoaders with help from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    train_transform=train_transform,\n",
        "    test_transform=test_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Create model with help from model_builder.py\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units=HIDDEN_UNITS,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',      # because we want to minimize validation loss\n",
        "    patience=2,      # wait 2 epochs before reducing LR\n",
        "    factor=0.5,      # multiply LR by 0.5 each time it plateaus\n",
        ")\n",
        "\n",
        "# Start training with help from engine.py\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs=NUM_EPOCHS,\n",
        "             device=device,\n",
        "             patience=7,\n",
        "             name=\"DuplicatedTinyVgg003\",\n",
        "             scheduler=scheduler)\n",
        "\n",
        "# Save the model with help from utils.py\n",
        "# utils.save_model(model=model,\n",
        "#                  target_dir=\"models\",\n",
        "#                  model_name=\"DuplicatedTinyVgg003.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNe3IsMjKpzH",
        "outputId": "cef1efd3-4f39-46ba-a7e8-ebb7c8ab3e62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99OqoXw00fXb",
        "outputId": "17dc63b4-ee11-4e46-a7ca-703149dcccbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/20 [00:00<?, ?it/s]Epoch: 1/20 | Train Loss: 1.0991 | Train Acc: 0.3125 | Val Loss: 1.1029 | Val Acc: 0.1979\n",
            "✅ Validation loss improved — best model saved.\n",
            "  5% 1/20 [00:02<00:43,  2.29s/it]Epoch: 2/20 | Train Loss: 1.0770 | Train Acc: 0.4258 | Val Loss: 1.1211 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 10% 2/20 [00:03<00:27,  1.54s/it]Epoch: 3/20 | Train Loss: 1.0998 | Train Acc: 0.2969 | Val Loss: 1.1251 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 2 epoch(s).\n",
            " 15% 3/20 [00:04<00:21,  1.29s/it]Epoch: 4/20 | Train Loss: 1.0691 | Train Acc: 0.3398 | Val Loss: 1.0929 | Val Acc: 0.3116\n",
            "✅ Validation loss improved — best model saved.\n",
            " 20% 4/20 [00:05<00:18,  1.17s/it]Epoch: 5/20 | Train Loss: 1.0109 | Train Acc: 0.5898 | Val Loss: 1.0707 | Val Acc: 0.3513\n",
            "✅ Validation loss improved — best model saved.\n",
            " 25% 5/20 [00:06<00:16,  1.10s/it]Epoch: 6/20 | Train Loss: 1.0176 | Train Acc: 0.4414 | Val Loss: 1.0623 | Val Acc: 0.3617\n",
            "✅ Validation loss improved — best model saved.\n",
            " 30% 6/20 [00:07<00:14,  1.06s/it]Epoch: 7/20 | Train Loss: 1.0143 | Train Acc: 0.4688 | Val Loss: 1.0582 | Val Acc: 0.3305\n",
            "✅ Validation loss improved — best model saved.\n",
            " 35% 7/20 [00:08<00:13,  1.05s/it]Epoch: 8/20 | Train Loss: 0.9467 | Train Acc: 0.6172 | Val Loss: 1.0541 | Val Acc: 0.2907\n",
            "✅ Validation loss improved — best model saved.\n",
            " 40% 8/20 [00:09<00:12,  1.06s/it]Epoch: 9/20 | Train Loss: 0.9462 | Train Acc: 0.5273 | Val Loss: 1.0375 | Val Acc: 0.3722\n",
            "✅ Validation loss improved — best model saved.\n",
            " 45% 9/20 [00:11<00:13,  1.25s/it]Epoch: 10/20 | Train Loss: 0.9986 | Train Acc: 0.5469 | Val Loss: 0.9884 | Val Acc: 0.5152\n",
            "✅ Validation loss improved — best model saved.\n",
            " 50% 10/20 [00:12<00:13,  1.38s/it]Epoch: 11/20 | Train Loss: 0.8933 | Train Acc: 0.6797 | Val Loss: 1.0231 | Val Acc: 0.4034\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 55% 11/20 [00:13<00:11,  1.27s/it]Epoch: 12/20 | Train Loss: 0.8453 | Train Acc: 0.6680 | Val Loss: 1.0615 | Val Acc: 0.3314\n",
            "⚠️ No improvement for 2 epoch(s).\n",
            " 60% 12/20 [00:14<00:09,  1.19s/it]Epoch: 13/20 | Train Loss: 1.1158 | Train Acc: 0.5312 | Val Loss: 1.0477 | Val Acc: 0.3428\n",
            "⚠️ No improvement for 3 epoch(s).\n",
            " 65% 13/20 [00:15<00:07,  1.13s/it]Epoch: 14/20 | Train Loss: 0.9942 | Train Acc: 0.5430 | Val Loss: 1.0356 | Val Acc: 0.3939\n",
            "⚠️ No improvement for 4 epoch(s).\n",
            " 70% 14/20 [00:16<00:06,  1.08s/it]Epoch: 15/20 | Train Loss: 0.8942 | Train Acc: 0.6758 | Val Loss: 1.0319 | Val Acc: 0.4034\n",
            "⚠️ No improvement for 5 epoch(s).\n",
            " 75% 15/20 [00:17<00:05,  1.13s/it]Epoch: 16/20 | Train Loss: 0.8947 | Train Acc: 0.6758 | Val Loss: 1.0303 | Val Acc: 0.3627\n",
            "⚠️ No improvement for 6 epoch(s).\n",
            " 80% 16/20 [00:19<00:04,  1.17s/it]Epoch: 17/20 | Train Loss: 0.8989 | Train Acc: 0.6641 | Val Loss: 1.0252 | Val Acc: 0.3523\n",
            "⚠️ No improvement for 7 epoch(s).\n",
            "\n",
            "⏹️ Early stopping triggered at epoch 17.\n",
            " 80% 16/20 [00:20<00:05,  1.28s/it]\n",
            "\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "!python3 going_modular/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KoD0sx58ZQf",
        "outputId": "bc8edce3-ac3f-4090-b983-8b4eff5ad84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/googlenet003.py\n"
          ]
        }
      ],
      "source": [
        "#now with transfer learning\n",
        "%%writefile going_modular/googlenet003.py\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRQKxlAf921I",
        "outputId": "d4af2780-9e1c-43dc-9742-53068edb66e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/transfer_train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/transfer_train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import data_setup, engine\n",
        "\n",
        "from torchvision import transforms,models\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY=1e-4\n",
        "# Setup directories\n",
        "train_dir = \"data/pizza_steak_sushi/train\"\n",
        "test_dir = \"data/pizza_steak_sushi/test\"\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Create DataLoaders with help from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    train_transform=train_transform,\n",
        "    test_transform=test_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# use googlenet pretrained model\n",
        "googlenet_model = models.googlenet(weights='DEFAULT')\n",
        "for param in googlenet_model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "# Replace the classifier head\n",
        "num_features = googlenet_model.fc.in_features\n",
        "googlenet_model.fc = nn.Linear(num_features, 3)\n",
        "googlenet_model.to(device)\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(googlenet_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',      # because we want to minimize validation loss\n",
        "    patience=2,      # wait 2 epochs before reducing LR\n",
        "    factor=0.5,      # multiply LR by 0.5 each time it plateaus\n",
        ")\n",
        "# Start training with help from engine.py\n",
        "engine.train(model=googlenet_model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs=NUM_EPOCHS,\n",
        "             device=device,\n",
        "             patience=7,\n",
        "             name=\"googlenet\",\n",
        "             scheduler=scheduler)\n",
        "\n",
        "# Save the model with help from utils.py\n",
        "# utils.save_model(model=model,\n",
        "#                  target_dir=\"models\",\n",
        "#                  model_name=\"googlenet_003.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhiMzpw0_Huq",
        "outputId": "2a8b4271-548e-4b74-e769-469827ea4f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/20 [00:00<?, ?it/s]Epoch: 1/20 | Train Loss: 0.8082 | Train Acc: 0.6328 | Val Loss: 0.6054 | Val Acc: 0.8551\n",
            "✅ Validation loss improved — best model saved.\n",
            "  5% 1/20 [00:02<00:56,  2.99s/it]Epoch: 2/20 | Train Loss: 0.6350 | Train Acc: 0.7812 | Val Loss: 0.6746 | Val Acc: 0.9062\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 10% 2/20 [00:06<00:56,  3.14s/it]Epoch: 3/20 | Train Loss: 0.4395 | Train Acc: 0.9492 | Val Loss: 0.5795 | Val Acc: 0.8750\n",
            "✅ Validation loss improved — best model saved.\n",
            " 15% 3/20 [00:08<00:49,  2.94s/it]Epoch: 4/20 | Train Loss: 0.4208 | Train Acc: 0.9727 | Val Loss: 0.4536 | Val Acc: 0.9280\n",
            "✅ Validation loss improved — best model saved.\n",
            " 20% 4/20 [00:11<00:42,  2.67s/it]Epoch: 5/20 | Train Loss: 0.6004 | Train Acc: 0.8477 | Val Loss: 0.4900 | Val Acc: 0.9271\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 25% 5/20 [00:13<00:37,  2.52s/it]Epoch: 6/20 | Train Loss: 0.5160 | Train Acc: 0.8477 | Val Loss: 0.5020 | Val Acc: 0.9072\n",
            "⚠️ No improvement for 2 epoch(s).\n",
            " 30% 6/20 [00:15<00:33,  2.41s/it]Epoch: 7/20 | Train Loss: 0.4901 | Train Acc: 0.8477 | Val Loss: 0.4231 | Val Acc: 0.9583\n",
            "✅ Validation loss improved — best model saved.\n",
            " 35% 7/20 [00:18<00:31,  2.39s/it]Epoch: 8/20 | Train Loss: 0.4872 | Train Acc: 0.8594 | Val Loss: 0.5045 | Val Acc: 0.9479\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 40% 8/20 [00:21<00:32,  2.71s/it]Epoch: 9/20 | Train Loss: 0.3987 | Train Acc: 0.9883 | Val Loss: 0.6143 | Val Acc: 0.8049\n",
            "⚠️ No improvement for 2 epoch(s).\n",
            " 45% 9/20 [00:23<00:28,  2.55s/it]Epoch: 10/20 | Train Loss: 0.4251 | Train Acc: 0.9648 | Val Loss: 0.5671 | Val Acc: 0.8655\n",
            "⚠️ No improvement for 3 epoch(s).\n",
            " 50% 10/20 [00:25<00:24,  2.42s/it]Epoch: 11/20 | Train Loss: 0.5932 | Train Acc: 0.8555 | Val Loss: 0.5470 | Val Acc: 0.8864\n",
            "⚠️ No improvement for 4 epoch(s).\n",
            " 55% 11/20 [00:27<00:21,  2.35s/it]Epoch: 12/20 | Train Loss: 0.3848 | Train Acc: 0.9961 | Val Loss: 0.6308 | Val Acc: 0.8059\n",
            "⚠️ No improvement for 5 epoch(s).\n",
            " 60% 12/20 [00:30<00:18,  2.29s/it]Epoch: 13/20 | Train Loss: 0.4876 | Train Acc: 0.8750 | Val Loss: 0.5341 | Val Acc: 0.8759\n",
            "⚠️ No improvement for 6 epoch(s).\n",
            " 65% 13/20 [00:32<00:16,  2.38s/it]Epoch: 14/20 | Train Loss: 0.3871 | Train Acc: 0.9961 | Val Loss: 0.4648 | Val Acc: 0.9271\n",
            "⚠️ No improvement for 7 epoch(s).\n",
            "\n",
            "⏹️ Early stopping triggered at epoch 14.\n",
            " 65% 13/20 [00:36<00:19,  2.78s/it]\n",
            "\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "!python3 going_modular/transfer_train.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/vision_transformer.py\n",
        "import torch\n",
        "from torch import nn\n",
        "class PatchEmbeding(nn.Module):\n",
        "    def __init__(self,\n",
        "                in_channels:int=3,\n",
        "                patch_size:int=16,\n",
        "                embed_dim:int=768):\n",
        "      super().__init__()\n",
        "      self.patch_size=patch_size\n",
        "      self.proj=nn.Conv2d(in_channels=in_channels,out_channels=embed_dim,kernel_size=patch_size,stride=patch_size,padding=0)\n",
        "      self.flatten=nn.Flatten(start_dim=2,end_dim=3)\n",
        "\n",
        "    def forward(self,x):\n",
        "      image_resolution=x.shape[-1]\n",
        "      assert image_resolution%self.patch_size==0,\"image size must be divisible by patch size\"\n",
        "      x=self.proj(x)\n",
        "      x=self.flatten(x)\n",
        "      return x.permute(0,2,1)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                embed_dim:int=768, # Hidden size D from Table 1 for ViT-Base\n",
        "                num_heads:int=12, # Heads from Table 1 for ViT-Base\n",
        "                attn_dropout:float=0): # doesn't look like the paper uses any dropout in MSABlocks\n",
        "      super().__init__()\n",
        "      self.layer_norm=nn.LayerNorm(normalized_shape=embed_dim)\n",
        "      self.multi_head_attention=nn.MultiheadAttention(embed_dim=embed_dim,num_heads=num_heads,dropout=attn_dropout,batch_first=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x=self.layer_norm(x)\n",
        "      atten_output,_=self.multi_head_attention(query=x,key=x,value=x,need_weights=False)\n",
        "      return atten_output\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self,\n",
        "              embed_dim:int=768, # Hidden Size D from Table 1 for ViT-Base\n",
        "              mlp_size:int=3072, # MLP size from Table 1 for ViT-Base\n",
        "              dropout:float=0.1): # Dropout from Table 3 for ViT-Base\n",
        "    super().__init__()\n",
        "    self.layer_norm=nn.LayerNorm(normalized_shape=embed_dim)\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(in_features=embed_dim,out_features=mlp_size),\n",
        "                nn.GELU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(in_features=mlp_size,out_features=embed_dim),\n",
        "        nn.Dropout(p=dropout)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.layer_norm(x)\n",
        "    x=self.mlp(x)\n",
        "    return x\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim:int=768, # Hidden size D from Table 1 for ViT-Base\n",
        "                 num_heads:int=12, # Heads from Table 1 for ViT-Base\n",
        "                 mlp_size:int=3072, # MLP size from Table 1 for ViT-Base\n",
        "                 mlp_dropout:float=0.1, # Amount of dropout for dense layers from Table 3 for ViT-Base\n",
        "                 attn_dropout:float=0): # Amount of dropout for attention layers\n",
        "        super().__init__()\n",
        "        self.msa_block=MultiHeadAttention(embed_dim=embed_dim,num_heads=num_heads,attn_dropout=attn_dropout)\n",
        "        self.mlp_block=MLP(embed_dim=embed_dim,mlp_size=mlp_size,dropout=mlp_dropout)\n",
        "    def forward(self,x):\n",
        "      x=self.msa_block(x)+x\n",
        "      x=self.mlp_block(x)+x\n",
        "      return x\n",
        "\n",
        "class Vit(nn.Module):\n",
        "      def __init__(self,\n",
        "                 img_size:int=224, # Training resolution from Table 3 in ViT paper\n",
        "                 in_channels:int=3, # Number of channels in input image\n",
        "                 patch_size:int=16, # Patch size\n",
        "                 num_transformer_layers:int=12, # Layers from Table 1 for ViT-Base\n",
        "                 embed_dim:int=768, # Hidden size D from Table 1 for ViT-Base\n",
        "                 mlp_size:int=3072, # MLP size from Table 1 for ViT-Base\n",
        "                 num_heads:int=12, # Heads from Table 1 for ViT-Base\n",
        "                 attn_dropout:float=0, # Dropout for attention projection\n",
        "                 mlp_dropout:float=0.1, # Dropout for dense/MLP layers\n",
        "                 embed_dropout:float=0.1, # Dropout for patch and position embeddings\n",
        "                 num_classes:int=1000): # Default for ImageNet but can customize this\n",
        "          super().__init__() # don't forget the super().__init__()!\n",
        "          assert img_size % patch_size==0, \"image size must be divisible by patch size\"\n",
        "          num_patches=(img_size//patch_size)**2\n",
        "          self.patch_embeding=PatchEmbeding(in_channels=in_channels,patch_size=patch_size,embed_dim=embed_dim)\n",
        "          self.cls_token=nn.Parameter(torch.randn(1,1,embed_dim))\n",
        "          self.position_embed=nn.Parameter(torch.randn(1,1+num_patches,embed_dim))\n",
        "          self.embed_dropout=nn.Dropout(p=embed_dropout)\n",
        "          self.transform_encoder=nn.Sequential(*[\n",
        "              TransformerBlock(embed_dim,num_heads,mlp_size,mlp_dropout,attn_dropout) for _ in range(num_transformer_layers)\n",
        "          ])\n",
        "          self.classifier=nn.Sequential(\n",
        "              nn.LayerNorm(normalized_shape=embed_dim),\n",
        "              nn.Linear(in_features=embed_dim,out_features=num_classes)\n",
        "          )\n",
        "      def forward(self,x):\n",
        "        batch_size=x.shape[0]\n",
        "        x=self.patch_embeding(x)\n",
        "        cls_token=self.cls_token.expand(batch_size,-1,-1)\n",
        "        x=torch.cat((cls_token,x),dim=1)\n",
        "        x=x+self.position_embed\n",
        "        x=self.embed_dropout(x)\n",
        "        x=self.transform_encoder(x)\n",
        "        cls_token_final=x[:,0]\n",
        "        return self.classifier(cls_token_final)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1qzkFovoQjJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1e29d5-bb9d-4fb4-bec8-ca518be3daed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/vision_transformer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/vit_train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import data_setup, engine, vision_transformer\n",
        "\n",
        "from torchvision import transforms,models\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY=1e-4\n",
        "# Setup directories\n",
        "train_dir = \"data/pizza_steak_sushi/train\"\n",
        "test_dir = \"data/pizza_steak_sushi/test\"\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Create DataLoaders with help from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    train_transform=train_transform,\n",
        "    test_transform=test_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# use vit model\n",
        "model = vision_transformer.Vit(num_classes=len(class_names)).to(device)\n",
        "\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',      # because we want to minimize validation loss\n",
        "    patience=2,      # wait 2 epochs before reducing LR\n",
        "    factor=0.5,      # multiply LR by 0.5 each time it plateaus\n",
        ")\n",
        "# Start training with help from engine.py\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs=NUM_EPOCHS,\n",
        "             device=device,\n",
        "             patience=7,\n",
        "             name=\"vit_003.pth\",\n",
        "             scheduler=scheduler)\n",
        "\n",
        "# Save the model with help from utils.py\n",
        "# utils.save_model(model=model,\n",
        "#                  target_dir=\"models\",\n",
        "#                  model_name=\"vit_003.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3QnyPfFG_i1",
        "outputId": "fa366e11-bffe-4c3f-d789-a36ab6f7509e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/vit_train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 going_modular/vit_train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-2-2u2MtO8",
        "outputId": "9bb4d602-42d6-485e-f5e1-af47c75d00f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/20 [00:00<?, ?it/s]Epoch: 1/20 | Train Loss: 3.8934 | Train Acc: 0.2852 | Val Loss: 1.3373 | Val Acc: 0.5417\n",
            "✅ Validation loss improved — best model saved.\n",
            "  5% 1/20 [00:10<03:22, 10.64s/it]Epoch: 2/20 | Train Loss: 1.5096 | Train Acc: 0.2852 | Val Loss: 1.1722 | Val Acc: 0.2604\n",
            "✅ Validation loss improved — best model saved.\n",
            " 10% 2/20 [00:20<02:59,  9.98s/it]Epoch: 3/20 | Train Loss: 1.5162 | Train Acc: 0.3008 | Val Loss: 1.1274 | Val Acc: 0.2604\n",
            "✅ Validation loss improved — best model saved.\n",
            " 15% 3/20 [00:29<02:43,  9.60s/it]Epoch: 4/20 | Train Loss: 1.4799 | Train Acc: 0.3047 | Val Loss: 1.2845 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 20% 4/20 [00:37<02:26,  9.19s/it]Epoch: 5/20 | Train Loss: 1.3653 | Train Acc: 0.2578 | Val Loss: 1.0514 | Val Acc: 0.5417\n",
            "✅ Validation loss improved — best model saved.\n",
            " 25% 5/20 [00:46<02:16,  9.12s/it]Epoch: 6/20 | Train Loss: 1.2040 | Train Acc: 0.3125 | Val Loss: 1.4341 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 30% 6/20 [00:55<02:05,  8.99s/it]Epoch: 7/20 | Train Loss: 1.1657 | Train Acc: 0.3984 | Val Loss: 1.0286 | Val Acc: 0.5417\n",
            "✅ Validation loss improved — best model saved.\n",
            " 35% 7/20 [01:09<02:17, 10.61s/it]Epoch: 8/20 | Train Loss: 1.2926 | Train Acc: 0.2695 | Val Loss: 1.1577 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 1 epoch(s).\n",
            " 40% 8/20 [01:18<01:59,  9.97s/it]Epoch: 9/20 | Train Loss: 1.0985 | Train Acc: 0.4180 | Val Loss: 1.0326 | Val Acc: 0.5417\n",
            "⚠️ No improvement for 2 epoch(s).\n",
            " 45% 9/20 [01:26<01:44,  9.54s/it]Epoch: 10/20 | Train Loss: 1.1935 | Train Acc: 0.2773 | Val Loss: 1.1150 | Val Acc: 0.2604\n",
            "⚠️ No improvement for 3 epoch(s).\n",
            " 50% 10/20 [01:35<01:33,  9.30s/it]Epoch: 11/20 | Train Loss: 1.0970 | Train Acc: 0.3086 | Val Loss: 1.1308 | Val Acc: 0.1875\n",
            "⚠️ No improvement for 4 epoch(s).\n",
            " 55% 11/20 [01:44<01:22,  9.15s/it]Epoch: 12/20 | Train Loss: 1.1424 | Train Acc: 0.2969 | Val Loss: 1.1180 | Val Acc: 0.1979\n",
            "⚠️ No improvement for 5 epoch(s).\n",
            " 60% 12/20 [01:52<01:12,  9.00s/it]Epoch: 13/20 | Train Loss: 1.1189 | Train Acc: 0.2773 | Val Loss: 1.0676 | Val Acc: 0.2604\n",
            "⚠️ No improvement for 6 epoch(s).\n",
            " 65% 13/20 [02:01<01:02,  8.92s/it]Epoch: 14/20 | Train Loss: 1.1414 | Train Acc: 0.3047 | Val Loss: 1.1173 | Val Acc: 0.2604\n",
            "⚠️ No improvement for 7 epoch(s).\n",
            "\n",
            "⏹️ Early stopping triggered at epoch 14.\n",
            " 65% 13/20 [02:10<01:10, 10.05s/it]\n",
            "\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O393Ww2mzZV",
        "outputId": "a861860c-87e1-45be-8b56-5a5089d1f836"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m_xzuI9inhRm",
        "outputId": "eebd16e7-08c7-4f1c-e9bb-1a5146891fc1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023flut_nlvG",
        "outputId": "526e6bbb-819b-4b05-8757-54d5d89dfa9c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 24 19:07:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}